{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Neural Network in Pytorch, Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully functional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    \n",
    "    def __init__(self, criterion):\n",
    "        super(Loss, self).__init__()\n",
    "        self.criterion = self.loss_function(criterion)\n",
    "    \n",
    "    def current_loss_function(self):\n",
    "        return self.criterion\n",
    "\n",
    "    def loss_function(self, criterion):\n",
    "        if criterion == 'cross_entropy':\n",
    "            return nn.CrossEntropyLoss()\n",
    "            \n",
    "        elif criterion == 'mse':\n",
    "            return nn.MSELoss()\n",
    "        \n",
    "        elif criterion == 'mae':\n",
    "            return nn.L1Loss()\n",
    "        \n",
    "class Activation(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation_type):\n",
    "        super(Activation, self).__init__()\n",
    "        self.activation_type = self.activation_func(activation_type)\n",
    "     \n",
    "    def activation_func(self, activation_type):\n",
    "        if activation_type == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation_type == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        elif activation_type == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation_type == 'leaky_relu':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation_type == 'softmax':\n",
    "            return nn.Softmax()\n",
    "        \n",
    "\n",
    "    def current_activation_function(self):\n",
    "        return self.activation_type\n",
    "    \n",
    "    \n",
    "class Optimizer(object):\n",
    "    \n",
    "    def __init__(self, model, optimizer_type, learning_rate):\n",
    "        super(Optimizer, self).__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model_params = model.parameters()\n",
    "        self.optimizer_type = self.optimizer(optimizer_type)\n",
    "    \n",
    "    def current_optimizer(self):\n",
    "        return self.optimizer_type\n",
    "    \n",
    "    def optimizer(self, optimizer_type):\n",
    "        \n",
    "        if optimizer_type == 'Adam':\n",
    "            return torch.optim.Adam(self.model_params, lr=self.learning_rate)\n",
    "            \n",
    "        elif optimizer_type == 'SGD':\n",
    "            return torch.optim.SGD(self.model_params, lr=self.learning_rate)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7767520dd5bd46378f7ed2a8ca7bd6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c17fce4fa4c44ef9576e34f512eb3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc5470e89134df79c754a9dc2d7d201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef6e4b398fb4ddaad004e6516fbb872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "torch.Size([100, 1, 28, 28])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrojose/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1607370249289/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.4334\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3424\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2636\n",
      "Epoch [1/2], Step [400/600], Loss: 0.2579\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1703\n",
      "Epoch [1/2], Step [600/600], Loss: 0.2855\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1818\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1302\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1182\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1500\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1557\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1358\n",
      "Accuracy of the network on the 10000 test images: 95.93 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#hyperparameters\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "hidden_size_two = 64\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                           transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                         transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "\n",
    "print(samples.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"class Layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, act_function):\n",
    "        super(Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.layer = nn.Linear(input_size, output_size)\n",
    "        self.activation_func = act_function\n",
    "        self.output_size = output_size\n",
    "    def input_size():\n",
    "        return self.input_size\n",
    "    \n",
    "    def output_size():\n",
    "        return self.output_size\n",
    "    \n",
    "    def layer(self):\n",
    "        return self.layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = self.activation_func().current_activation_function(out)\n",
    "        return out\"\"\"\n",
    "        \n",
    "        \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size_two, num_classes, act_function):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        #self.layers = []\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        #self.relu = nn.ReLU()\n",
    "        self.act_func = act_function\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size_two)  \n",
    "        self.act_func = act_function\n",
    "        self.l3 = nn.Linear(hidden_size_two, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        #out = self.relu(out)\n",
    "        out = self.act_func(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.act_func(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "\n",
    "act_func = Activation('relu').current_activation_function()\n",
    "model = NeuralNet(input_size, hidden_size, hidden_size_two, num_classes, act_func).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "#model.forward\n",
    "criterion = Loss('cross_entropy').current_loss_function()#nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "optimizer = Optimizer(model, 'Adam', learning_rate=learning_rate).current_optimizer()\n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        #optimizer.optimize(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
