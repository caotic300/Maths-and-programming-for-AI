{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network, Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "X_train:  (60000, 784)\n",
      "y_train:  (60000, 10)\n",
      "X_test:  (10000, 784)\n",
      "y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X = X/255\n",
    "X = X.astype('float32')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "def one_hot(y, cat, dtype=np.float32):\n",
    "    return np.array(y[:, None] == np.arange(cat), dtype)\n",
    "y_new = one_hot(y.astype('int32'), 10)\n",
    "\n",
    "# Splitting Dataset\n",
    "split = 60000\n",
    "\n",
    "X_train = X[:split]\n",
    "y_train = y_new[:split]\n",
    "\n",
    "X_test = X[split:]\n",
    "y_test = y_new[split:]\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Neural Network class.\n",
    "\n",
    "We made the neural network class. We have only one class, we tried different methods of refactoring the idea was to:\n",
    "\n",
    "- make different classes for different optimizers\n",
    "- make different classed for different loss functions \n",
    "- combine the functionality on the Task2 class and pass them to the other classes to provide the functionality required. \n",
    "\n",
    "However, we did try those methods, but when we tried to refactore it we found that the code was not working properly, and we did not have enough time to implement it. Therefore we decided to leave what was working. \n",
    "\n",
    "#### Reflexion\n",
    "\n",
    "Making the classes we wanted to do takes a lot of thinking about the design of the architecture, such as what to use as parameters, how to link different classes between each other and how to call the different methods and what design patterns to use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task2(object):\n",
    "    \n",
    "    def __init__(self, layers, act_func, epochs, learn_r):\n",
    "        self.layers = layers        # List of nodes in each layer\n",
    "        self.epochs = epochs        # Number of Epochs \n",
    "        self.learn_r = learn_r      # Learning rate applied to optimizer\n",
    "        \n",
    "        self.Errors = []            # List to keep track of errors calculated\n",
    "        self.Epochs = []            # List to keep track of iterations \n",
    "        self.Loss = []              # List to keep track of loss throughout training\n",
    "        self.Cost = []              # List to keep track of loss throughout training\n",
    "        \n",
    "        self.func  = act_func                                     # Activation function chosen \n",
    "        self.funcs = {'sigmoid': self.sigmoid, 'relu': self.relu} # Dictionary to correpond to chosen activation funciton\n",
    "        \n",
    "        # dictionary to keep track of weights\n",
    "        self.network = self.instantiate()   \n",
    "\n",
    "# Sigmoid function to be applied to input/hidden layers \n",
    "# Output 1 as x -> +∞ | 0 as x -> -∞\n",
    "    def sigmoid(self, z, isDeriv):\n",
    "        if isDeriv: # When backpropagating\n",
    "            return (np.exp(-z)) / ((np.exp(-z) + 1 )**2)\n",
    "        \n",
    "        return 1 / (1 + np.exp(-z)) # Forward feed\n",
    "    \n",
    "# Relu function can also be applied to input/hidden layers\n",
    "    def relu(self, z, isDeriv):\n",
    "        t = np.ones((len(z))) \n",
    "        if isDeriv: \n",
    "            for i in range(len(z)):\n",
    "                if z[i] >= 0:\n",
    "                    t[i] = 1\n",
    "                else:\n",
    "                    t[i] = 0\n",
    "            return t\n",
    "        \n",
    "        r = np.maximum(0, z)\n",
    "        return r\n",
    "    \n",
    "# Softmax function to be applied to the output layer \n",
    "    def softmax(self, z, isDeriv):\n",
    "        expo = np.exp(z - z.max())\n",
    "        \n",
    "        if isDeriv: # When backpropagating\n",
    "            return expo / np.sum(expo, axis=0) * (1 - expo / np.sum(expo, axis=0))\n",
    "        \n",
    "        return expo / np.sum(expo, axis = 0) # Forward feed\n",
    "    \n",
    "    def cross_entropy(self, ytrain, output):\n",
    "        L_sum = np.sum(np.multiply(ytrain, np.log(output)))\n",
    "        L = -(1/ytrain.shape[0]) * L_sum        # L = -(1/m) . sum (y . log y^)\n",
    "        return L\n",
    "    \n",
    "    def instantiate(self):\n",
    "        \n",
    "        # Input Layer, Hidden Layer, Hidden Layer, Output Layer\n",
    "        inputLayer = self.layers[0]\n",
    "        hiddenLayer = self.layers[1]\n",
    "        hiddenLayer2 = self.layers[2]\n",
    "        outputLayer = self.layers[3]\n",
    "        \n",
    "        network = {\n",
    "                    'W1' : np.random.randn(hiddenLayer, inputLayer) * np.sqrt(1.0/hiddenLayer),     # Weight for Input -> Hidden 1\n",
    "                    'W2' : np.random.randn(hiddenLayer2, hiddenLayer) * np.sqrt(1.0/hiddenLayer2),  # Weight for hidden 1 -> Hidden 2\n",
    "                    'W3' : np.random.randn(outputLayer, hiddenLayer2) * np.sqrt(1.0/outputLayer)   # Weight for Hidden 2 -> Output\n",
    "                    \n",
    "                    #,'b1' : np.zeros((hiddenLayer, 1)) * np.sqrt(1.0/inputLayer),                    # Bias used in W1\n",
    "                    #'b2' : np.zeros((hiddenLayer2, 1)) * np.sqrt(1.0/hiddenLayer),                  # Bias used in W2\n",
    "                    #'b3' : np.zeros((outputLayer, 1)) * np.sqrt(1.0/hiddenLayer2)                   # Bias used in W3\n",
    "                    \n",
    "                  }\n",
    "\n",
    "        return network\n",
    "\n",
    "    def forward(self, X_train):\n",
    "        \n",
    "        network = self.network\n",
    "        f = self.func   # Activation function chosen\n",
    "        fs = self.funcs # Dictionary of activation functions\n",
    "        \n",
    "        # Input Layer\n",
    "        network['A0'] = X_train\n",
    "        \n",
    "        # Input -> Hidden\n",
    "        network['Z1'] = np.dot(network[\"W1\"], network['A0']) #+ network['b1']\n",
    "        network['A1'] = fs[f](network['Z1'], isDeriv = False)\n",
    "        \n",
    "        # Hidden Layer 1 -> Hidden Layer 2\n",
    "        network['Z2'] = np.dot(network[\"W2\"], network['A1']) #+ network['b2']\n",
    "        network['A2'] = fs[f](network['Z2'], isDeriv = False)\n",
    "\n",
    "        # Hidden Layer 2 -> Output\n",
    "        network['Z3'] = np.dot(network[\"W3\"], network['A2']) #+ network['b3']\n",
    "        network['A3'] = self.softmax(network['Z3'], isDeriv = False)\n",
    "\n",
    "        return network['A3']    # Return output\n",
    "\n",
    "    def backward(self, y_train, output):\n",
    "        \n",
    "        update = {}                 # Dictionary to hold changes to weights \n",
    "        network = self.network        \n",
    "        Errors = self.Errors\n",
    "        Loss = self.Loss        \n",
    "        f = self.func                \n",
    "        fs = self.funcs             \n",
    "        \n",
    "        # Error: subtract target array from the output of a forward propagation\n",
    "        loss = self.cross_entropy(y_train, output)\n",
    "        Loss.append(loss)\n",
    "        \n",
    "        # Update from Softmax Output \n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(network['Z3']\n",
    "                                                                    , isDeriv = True)\n",
    "        Errors.append(error)\n",
    "        update['W3'] = np.outer(error, network['A2'])\n",
    "        \n",
    "        # Update Hidden Layer 2                  ↓ Call activation function from dictionary\n",
    "        error = np.dot(network['W3'].T, error) * fs[f](network['Z2']\n",
    "                                                   , isDeriv = True)\n",
    "        Errors.append(error)\n",
    "        update['W2'] = np.outer(error, network['A1'])\n",
    "\n",
    "        # Update from Hidden Layer 1             ↓ Call activation function from dictionary\n",
    "        error = np.dot(network['W2'].T, error) * fs[f](network['Z1'], isDeriv = True)\n",
    "        Errors.append(error)       \n",
    "        update['W1'] = np.outer(error, network['A0'])\n",
    "\n",
    "        return update        # Return updated dictionary \n",
    "\n",
    "    def optimizer(self, gradient):\n",
    "        # Stochastic Gradient Descent\n",
    "        for theta, grad in gradient.items():\n",
    "            self.network[theta] -= self.learn_r * grad\n",
    "\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        predict = []\n",
    "        \n",
    "        for x, y in zip(X_test, y_test):\n",
    "            output = self.forward(x)                # Forward feed\n",
    "            pred = np.argmax(output)                # Return index of max value in output\n",
    "            predict.append(pred == np.argmax(y))    # Add highest predicted value to list\n",
    "            mean = np.mean(predict)                 # Calculate mean of values in list\n",
    "        \n",
    "        return mean        # Return overall accuracy \n",
    "\n",
    "    def train_network(self, X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        for i in range(self.epochs):                \n",
    "            for x,y in zip(X_train, y_train):\n",
    "                output = self.forward(x)\n",
    "                gradient = self.backward(y, output)\n",
    "                self.optimizer(gradient)\n",
    "                self.Epochs.append(i)\n",
    "            \n",
    "            accuracy = self.accuracy(X_test, y_test)\n",
    "            print(\"Epoch: \", i + 1, \" - Accuracy: \", accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainig and Testing the Neural Network.\n",
    "\n",
    "We used the train_network method to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  - Accuracy:  69.37 %\n",
      "Epoch:  2  - Accuracy:  79.64 %\n",
      "Epoch:  3  - Accuracy:  81.64 %\n",
      "Epoch:  4  - Accuracy:  82.44 %\n",
      "Epoch:  5  - Accuracy:  88.29 %\n",
      "Epoch:  6  - Accuracy:  87.39 %\n",
      "Epoch:  7  - Accuracy:  86.78 %\n",
      "Epoch:  8  - Accuracy:  86.86 %\n",
      "Epoch:  9  - Accuracy:  87.16000000000001 %\n",
      "Epoch:  10  - Accuracy:  86.79 %\n"
     ]
    }
   ],
   "source": [
    "NN = Task2(  layers = [784, 256, 128, 10], act_func = 'sigmoid',\n",
    "             epochs = 10, learn_r = 0.01)\n",
    "\n",
    "NN.train_network(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "\n",
    "WE are going to plot how the loss function changes as the number of Epochs is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################\n",
    "#               PLOTTING               #\n",
    "########################################\n",
    "\n",
    "# Calculated Loss over every iteration\n",
    "losses = NN.Loss\n",
    "#print(losses)\n",
    "\n",
    "plt.plot(losses, 'r-')\n",
    "plt.xlabel('Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
